[
  {
    "model_name": "DeepSeek-V3.2-Reasoner",
    "published_param_count_b": null,
    "learnable_params_b": 671.1,
    "active_params_b": 37.7,
    "architecture": "MoE",
    "context_length": 163840,
    "precision": "FP8",
    "attention_type": "MLA",
    "num_hidden_layers": 61,
    "num_kv_layers": null,
    "num_kv_heads": null,
    "head_dim": null,
    "routed_expert_params_b": 653.9,
    "kv_lora_rank": 512,
    "qk_rope_head_dim": 64,
    "hf_model_id": "deepseek-ai/DeepSeek-V3.2-Speciale"
  },
  {
    "model_name": "GLM-4.7",
    "published_param_count_b": null,
    "learnable_params_b": 352.8,
    "active_params_b": 33.7,
    "architecture": "MoE",
    "context_length": 202752,
    "precision": "BF16",
    "attention_type": "GQA",
    "num_hidden_layers": 92,
    "num_kv_layers": null,
    "num_kv_heads": 8,
    "head_dim": 128,
    "routed_expert_params_b": 336.0,
    "kv_lora_rank": null,
    "qk_rope_head_dim": null,
    "hf_model_id": "zai-org/GLM-4.7"
  },
  {
    "model_name": "Kimi-K2-Thinking",
    "published_param_count_b": null,
    "learnable_params_b": 1026.4,
    "active_params_b": 32.9,
    "architecture": "MoE",
    "context_length": 262144,
    "precision": "INT4",
    "attention_type": "MLA",
    "num_hidden_layers": 61,
    "num_kv_layers": null,
    "num_kv_heads": null,
    "head_dim": null,
    "routed_expert_params_b": 1014.7,
    "kv_lora_rank": 512,
    "qk_rope_head_dim": 64,
    "hf_model_id": "moonshotai/Kimi-K2-Thinking"
  },
  {
    "model_name": "Kimi-K2.5",
    "published_param_count_b": 170.7,
    "learnable_params_b": 1026.4,
    "active_params_b": 32.9,
    "architecture": "MoE",
    "context_length": 262144,
    "precision": "INT4",
    "attention_type": "MLA",
    "num_hidden_layers": 61,
    "num_kv_layers": null,
    "num_kv_heads": null,
    "head_dim": null,
    "routed_expert_params_b": 1014.7,
    "kv_lora_rank": 512,
    "qk_rope_head_dim": 64,
    "hf_model_id": "moonshotai/Kimi-K2.5"
  },
  {
    "model_name": "MiniMax-M2.1",
    "published_param_count_b": null,
    "learnable_params_b": 228.7,
    "active_params_b": 11.1,
    "architecture": "MoE",
    "context_length": 196608,
    "precision": "FP8",
    "attention_type": "GQA",
    "num_hidden_layers": 62,
    "num_kv_layers": null,
    "num_kv_heads": 8,
    "head_dim": 128,
    "routed_expert_params_b": 224.7,
    "kv_lora_rank": null,
    "qk_rope_head_dim": null,
    "hf_model_id": "MiniMaxAI/MiniMax-M2.1"
  },
  {
    "model_name": "MiniMax-M2.5",
    "published_param_count_b": null,
    "learnable_params_b": 228.7,
    "active_params_b": 11.1,
    "architecture": "MoE",
    "context_length": 196608,
    "precision": "FP8",
    "attention_type": "GQA",
    "num_hidden_layers": 62,
    "num_kv_layers": null,
    "num_kv_heads": 8,
    "head_dim": 128,
    "routed_expert_params_b": 224.7,
    "kv_lora_rank": null,
    "qk_rope_head_dim": null,
    "hf_model_id": "MiniMaxAI/MiniMax-M2.5"
  },
  {
    "model_name": "Nemotron-3-Nano",
    "published_param_count_b": 31.6,
    "learnable_params_b": 31.5,
    "active_params_b": 3.5,
    "architecture": "MoE",
    "context_length": 262144,
    "precision": "BF16",
    "attention_type": "GQA",
    "num_hidden_layers": 52,
    "num_kv_layers": 6,
    "num_kv_heads": 2,
    "head_dim": 128,
    "routed_expert_params_b": 29.4,
    "kv_lora_rank": null,
    "qk_rope_head_dim": null,
    "hf_model_id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8"
  },
  {
    "model_name": "Qwen3-Coder-480B",
    "published_param_count_b": null,
    "learnable_params_b": 480.2,
    "active_params_b": 35.5,
    "architecture": "MoE",
    "context_length": 262144,
    "precision": "BF16",
    "attention_type": "GQA",
    "num_hidden_layers": 62,
    "num_kv_layers": null,
    "num_kv_heads": 8,
    "head_dim": 128,
    "routed_expert_params_b": 468.1,
    "kv_lora_rank": null,
    "qk_rope_head_dim": null,
    "hf_model_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct"
  }
]